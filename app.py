import requests
from requests_toolbelt import MultipartEncoder
import os
import time
import json
import contextlib
import mimetypes
from flask import Flask, render_template, request, send_file, jsonify
import tempfile
import shutil
import re
import base64
from io import BytesIO
from config import Config

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max file size

# åˆ›å»ºå®‰å…¨çš„ä¸Šä¼ ç›®å½• (ä½¿ç”¨ /tmp ç›®å½•ï¼Œå› ä¸º /app åœ¨å®¹å™¨ä¸­æ˜¯åªè¯»çš„)
import os
UPLOAD_DIR = '/tmp/uploads'
DEBUG_DIR = '/tmp/debug_logs'

# ç¡®ä¿ç›®å½•å­˜åœ¨å¹¶è®¾ç½®æƒé™
for directory in [UPLOAD_DIR, DEBUG_DIR]:
    if not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)
        # è®¾ç½®ç›®å½•æƒé™ä¸º755 (rwxr-xr-x)
        os.chmod(directory, 0o755)

app.config['UPLOAD_FOLDER'] = UPLOAD_DIR

# ç¦ç”¨Flaskçš„é»˜è®¤å®‰å…¨å¤´
app.config['SESSION_COOKIE_SECURE'] = False
app.config['SESSION_COOKIE_HTTPONLY'] = False

# æ·»åŠ CORSæ”¯æŒ
@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
    return response


def _to_bool(value, default=False):
    if value is None:
        return default
    if isinstance(value, bool):
        return value
    return str(value).strip().lower() in {"true", "1", "yes", "on"}


def parse_pdf_with_mineru(filepath, options=None, api_token=None):
    """ä½¿ç”¨MinerU APIè§£æPDF"""
    from config import Config
    
    # ä½¿ç”¨ä¼ å…¥çš„tokenæˆ–é…ç½®æ–‡ä»¶ä¸­çš„token
    token = api_token or Config.MINERU_API_TOKEN
    api_url = Config.MINERU_API_URL
    
    base_payload = {
        "model": "MinerU2.5",
        "is_ocr": True,
        "include_image_base64": True,
        "formula_enable": True,
        "table_enable": True,
        "layout_model": "doclayout_yolo",
        "output_format": "md"
    }

    payload = base_payload.copy()
    if options:
        for key, value in options.items():
            if value is not None:
                payload[key] = value
    
    # è°ƒè¯•ï¼šæ‰“å° payload
    print("\n" + "=" * 50)
    print("æ„å»ºçš„ payload:")
    for k, v in payload.items():
        print(f"  {k}: {v} (type: {type(v).__name__})")
    print("=" * 50 + "\n")

    fields = []
    for key in [
        "model",
        "is_ocr",
        "include_image_base64",
        "formula_enable",
        "table_enable",
        "layout_model",
        "output_format",
        "end_pages",
        "language"
    ]:
        if key not in payload:
            continue
        value = payload[key]
        if isinstance(value, bool):
            value = str(value).lower()
        elif value is None:
            continue
        # è·³è¿‡ç©ºå­—ç¬¦ä¸²ï¼ˆç‰¹åˆ«æ˜¯ end_pages ç­‰å¯é€‰å‚æ•°ï¼‰
        elif isinstance(value, str) and not value.strip():
            continue
        fields.append((key, str(value)))

    # æ‰“å°å®é™…å‘é€çš„å­—æ®µï¼ˆç”¨äºè°ƒè¯•ï¼‰
    print("=" * 50)
    print("å‘é€åˆ° MinerU API çš„å‚æ•°:")
    for key, value in fields:
        print(f"  {key}: {value}")
    print(f"ä½¿ç”¨API Token: {token[:10]}..." if token else "æœªé…ç½®Token")
    print("=" * 50)
    
    with contextlib.ExitStack() as stack:
        name = os.path.basename(filepath)
        mime_type, _ = mimetypes.guess_type(filepath)
        fields.append(("file", (name, stack.enter_context(open(filepath, "rb")),
                                mime_type or "application/octet-stream")))
        encoder = MultipartEncoder(fields)
        
        # ä½¿ç”¨åŠ¨æ€çš„headers
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": encoder.content_type
        }
        
        response = requests.post(api_url, headers=headers, data=encoder)
        return response.json()


def poll_mineru_task(task_id, api_token=None):
    """è½®è¯¢MinerUä»»åŠ¡çŠ¶æ€"""
    from config import Config

    # ä½¿ç”¨ä¼ å…¥çš„tokenæˆ–é…ç½®æ–‡ä»¶ä¸­çš„token
    token = api_token or Config.MINERU_API_TOKEN

    # åŠ¨æ€æ„å»ºçŠ¶æ€æŸ¥è¯¢URLï¼ˆåŸºäºAPIçš„base URLï¼‰
    status_url = f"https://ai.gitee.com/v1/task/{task_id}"

    # å‡å°‘æ€»è¶…æ—¶æ—¶é—´åˆ°10åˆ†é’Ÿï¼Œæ›´é€‚åˆäº‘ç¯å¢ƒ
    timeout = 10 * 60  # 10åˆ†é’Ÿ
    retry_interval = 3  # 3ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œå‡å°‘é˜»å¡æ—¶é—´
    attempts = 0
    max_attempts = int(timeout / retry_interval)

    # æ„å»ºheaders
    headers = {
        "Authorization": f"Bearer {token}"
    }

    print(f"å¼€å§‹è½®è¯¢ä»»åŠ¡çŠ¶æ€ï¼Œæ€»è¶…æ—¶: {timeout//60}åˆ†é’Ÿ...")

    while attempts < max_attempts:
        attempts += 1

        # æ¯30æ¬¡æ£€æŸ¥ï¼ˆ90ç§’ï¼‰æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
        if attempts % 30 == 1:
            elapsed = (attempts - 1) * retry_interval
            print(f"  ğŸ“Š å·²ç­‰å¾… {elapsed//60}åˆ†{elapsed%60}ç§’ï¼Œæ­£åœ¨å¤„ç†PDF...")

        try:
            response = requests.get(status_url, headers=headers, timeout=10)
            result = response.json()

            if result.get("error"):
                print(f"  âŒ APIé”™è¯¯: {result['error']}: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                raise ValueError(f"{result['error']}: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")

            status = result.get("status", "unknown")

            if status == "success":
                print("  âœ… ä»»åŠ¡å®Œæˆï¼")
                # ä¿å­˜å®Œæ•´ç»“æœåˆ°æ–‡ä»¶ç”¨äºè°ƒè¯•
                debug_dir = '/tmp/debug_logs'
                if not os.path.exists(debug_dir):
                    os.makedirs(debug_dir, exist_ok=True)
                debug_file = os.path.join(debug_dir, f"mineru_result_{task_id}.json")
                try:
                    with open(debug_file, 'w', encoding='utf-8') as f:
                        json.dump(result, f, indent=2, ensure_ascii=False)
                    print(f"  ğŸ“„ è°ƒè¯•æ–‡ä»¶å·²ä¿å­˜: {debug_file}")
                except Exception as e:
                    print(f"  âš ï¸ æ— æ³•ä¿å­˜è°ƒè¯•æ–‡ä»¶: {e}")
                return result
            elif status in ["failed", "cancelled"]:
                print(f"  âŒ ä»»åŠ¡{status}")
                raise ValueError(f"ä»»åŠ¡{status}")
            else:
                # çŸ­æš‚ä¼‘çœ ï¼Œé¿å…è¿‡åº¦å ç”¨èµ„æº
                time.sleep(retry_interval)
                continue

        except requests.exceptions.RequestException as e:
            print(f"  âš ï¸ ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œé‡è¯•ä¸­: {e}")
            time.sleep(retry_interval)
            continue

    print(f"  â° ä»»åŠ¡è¶…æ—¶ (å·²ç­‰å¾… {timeout//60}åˆ†é’Ÿ)")
    raise TimeoutError(f"ä»»åŠ¡å¤„ç†è¶…æ—¶ï¼Œå·²ç­‰å¾… {timeout//60} åˆ†é’Ÿ")


def translate_with_ai(text, source_lang="EN", target_lang="ZH", api_url=None, api_key=None, model=None, max_retries=None):
    """ä½¿ç”¨AI APIç¿»è¯‘æ–‡æœ¬å¹¶å¤„ç†æ•°å­¦å…¬å¼ï¼Œæ”¯æŒè‡ªåŠ¨é‡è¯•"""
    from config import Config
    import time
    
    if not text or not text.strip():
        return text
    
    # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
    translate_api_url = api_url or Config.AI_TRANSLATE_API_URL
    translate_api_key = api_key or Config.AI_TRANSLATE_API_KEY
    translate_model = model or Config.AI_TRANSLATE_MODEL
    max_retries = max_retries or Config.AI_TRANSLATE_MAX_RETRIES
    
    # å¤„ç†API URLï¼šå¦‚æœç”¨æˆ·åªè¾“å…¥äº†åŸºç¡€URLï¼Œè‡ªåŠ¨æ·»åŠ endpoint
    if translate_api_url and not translate_api_url.endswith('/chat/completions'):
        # ç§»é™¤æœ«å°¾çš„æ–œæ 
        translate_api_url = translate_api_url.rstrip('/')
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ /v1 åç¼€
        if not translate_api_url.endswith('/v1'):
            translate_api_url += '/v1'
        # æ·»åŠ  /chat/completions
        translate_api_url += '/chat/completions'
        print(f"âœ“ è‡ªåŠ¨è¡¥å…¨ç¿»è¯‘API URL: {translate_api_url}", flush=True)
    
    # æ„å»ºç³»ç»Ÿæç¤º
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡ç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†è‹±æ–‡å­¦æœ¯å†…å®¹ç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š

## æ ¸å¿ƒè¦æ±‚
1. **å®Œæ•´ç¿»è¯‘**ï¼šå¿…é¡»ç¿»è¯‘æ‰€æœ‰è‹±æ–‡å†…å®¹ï¼Œä¸è¦é—æ¼ä»»ä½•æ®µè½ã€å¥å­æˆ–çŸ­è¯­
2. **ç¿»è¯‘è´¨é‡**ï¼šä½¿ç”¨å‡†ç¡®ã€æµç•…çš„å­¦æœ¯ä¸­æ–‡ï¼Œä¿æŒä¸“ä¸šæ€§
3. **å®Œå…¨æ¸…é™¤æ–¹æ¡†å­—ç¬¦**ï¼šæ–‡æœ¬ä¸­ä»»ä½•æ˜¾ç¤ºä¸ºæ–¹æ¡†(â–¡)çš„å­—ç¬¦éƒ½å¿…é¡»è¢«ç§»é™¤æˆ–æ›¿æ¢ä¸ºæ­£ç¡®çš„å­—ç¬¦
4. **æ­£ç¡®å¤„ç†å‚è€ƒæ–‡çŒ®æ ‡æ³¨**ï¼šä¸Šæ ‡æ•°å­—ä¹‹é—´ä¸è¦æœ‰ç©ºæ ¼æˆ–å…¶ä»–å­—ç¬¦

## æ•°å­¦å…¬å¼å¤„ç†ï¼ˆå…³é”®ï¼ï¼‰
å°†æ‰€æœ‰LaTeXæ•°å­¦å…¬å¼è½¬æ¢ä¸ºUnicodeæ ¼å¼ï¼Œå…·ä½“è§„åˆ™ï¼š

### ä¸Šæ ‡ï¼ˆSuperscriptsï¼‰
- æ•°å­—ï¼šâ° Â¹ Â² Â³ â´ âµ â¶ â· â¸ â¹
- ç¬¦å·ï¼šâº â» â¼ â½ â¾
- ç¤ºä¾‹ï¼š$^{13}C$ â†’ Â¹Â³Cï¼Œ$^{12-14}$ â†’ Â¹Â²â»Â¹â´ï¼Œ$^{2,18}$ â†’ Â²,Â¹â¸

### ä¸‹æ ‡ï¼ˆSubscriptsï¼‰
- æ•°å­—ï¼šâ‚€ â‚ â‚‚ â‚ƒ â‚„ â‚… â‚† â‚‡ â‚ˆ â‚‰
- ç¬¦å·ï¼šâ‚Š â‚‹ â‚Œ â‚ â‚
- ç¤ºä¾‹ï¼š$O_2$ â†’ Oâ‚‚ï¼Œ$H_2O$ â†’ Hâ‚‚O

### å¸Œè…Šå­—æ¯
Î± Î² Î³ Î´ Îµ Î¶ Î· Î¸ Î¹ Îº Î» Î¼ Î½ Î¾ Î¿ Ï€ Ï Ïƒ Ï„ Ï… Ï† Ï‡ Ïˆ Ï‰
Î‘ Î’ Î“ Î” Î• Î– Î— Î˜ Î™ Îš Î› Îœ Î Î ÎŸ Î  Î¡ Î£ Î¤ Î¥ Î¦ Î§ Î¨ Î©

### æ•°å­¦ç¬¦å·
Â± âˆ“ Ã— Â· Ã· â‰¤ â‰¥ â‰  â‰ˆ â‰¡ âˆ âˆ‘ âˆ âˆ« âˆ‚ âˆ‡ âˆš âˆ¼ â‰ª â‰«

## ç‰¹æ®Šå¤„ç†
1. **ä½œè€…ä¸Šæ ‡**ï¼šå¦‚ "Wang $^{1,2,3}$" â†’ "Wang Â¹,Â²,Â³"ï¼ˆæ³¨æ„ï¼šæ•°å­—ä¹‹é—´åªç”¨é€—å·ï¼Œä¸è¦æœ‰ç©ºæ ¼æˆ–å…¶ä»–å­—ç¬¦ï¼‰
2. **æ³¢æµªå·**ï¼š$\\sim$ æˆ– ~ â†’ âˆ¼ï¼ˆä½¿ç”¨Unicodeæ³¢æµªå· U+223Cï¼‰
3. **èŒƒå›´æ ‡æ³¨**ï¼šå¦‚ $^{13-15}$ â†’ Â¹Â³â»Â¹âµï¼ˆä½¿ç”¨Unicodeä¸Šæ ‡å‡å·ï¼‰
4. **ç™¾åˆ†å·**ï¼šâ€°ï¼ˆåƒåˆ†å·ï¼‰ä¿æŒä¸å˜

## æ ¼å¼ä¿æŒ
- ä¿ç•™æ‰€æœ‰Markdownæ ‡è®°ï¼š# ## ### * ** [] () ç­‰
- ä¿æŒæ®µè½å’Œæ¢è¡Œç»“æ„
- å›¾ç‰‡æ ‡è®°ä¿æŒåŸæ ·

## ä¸è¦ç¿»è¯‘
- äººåã€åœ°å
- æœŸåˆŠåã€æœºæ„å
- å›¾ç‰‡çš„base64æ•°æ®
- å·²ç»æ˜¯ä¸­æ–‡çš„å†…å®¹

## è¾“å‡ºè¦æ±‚
**å¿…é¡»å®Œæ•´ç¿»è¯‘æ‰€æœ‰å†…å®¹ï¼** ç¡®ä¿è¾“å‡ºåŒ…å«è¾“å…¥ä¸­çš„æ¯ä¸€ä¸ªæ®µè½ã€æ¯ä¸€å¥è¯ã€‚

åªè¿”å›ç¿»è¯‘åçš„çº¯æ–‡æœ¬å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜ã€è§£é‡Šæˆ–å…ƒä¿¡æ¯ã€‚

**ä¸¥æ ¼ç¦æ­¢ï¼š**
- âŒ ä¸è¦ä½¿ç”¨HTMLæ ‡ç­¾ï¼ˆå¦‚ <sup>ã€<sub>ã€<b>ã€<i> ç­‰ï¼‰
- âŒ ä¸è¦æœ‰æ–¹æ¡†å­—ç¬¦(â–¡)
- âŒ ä¸è¦æœ‰ä»»ä½•å…¶ä»–æ ‡è®°è¯­è¨€
- âŒ ä¸è¦é—æ¼ä»»ä½•æ®µè½æˆ–å¥å­

**å¿…é¡»ä½¿ç”¨ï¼š**
- âœ… Unicodeä¸Šæ ‡å­—ç¬¦ï¼šâ°Â¹Â²Â³â´âµâ¶â·â¸â¹âºâ»
- âœ… Unicodeä¸‹æ ‡å­—ç¬¦ï¼šâ‚€â‚â‚‚â‚ƒâ‚„â‚…â‚†â‚‡â‚ˆâ‚‰â‚Šâ‚‹
- âœ… çº¯æ–‡æœ¬æ ¼å¼
- âœ… ç¿»è¯‘æ‰€æœ‰è‹±æ–‡å†…å®¹

**æ£€æŸ¥æ¸…å•ï¼š**
- [ ] æ‰€æœ‰æ®µè½éƒ½å·²ç¿»è¯‘
- [ ] æ²¡æœ‰è‹±æ–‡å¥å­æ®‹ç•™
- [ ] ä¿æŒäº†åŸæ–‡çš„å®Œæ•´ç»“æ„"""

    # æ„å»ºè¯·æ±‚
    headers = {
        "Authorization": f"Bearer {translate_api_key}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": translate_model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": text}
        ],
        "max_tokens": Config.AI_TRANSLATE_MAX_TOKENS,
        "temperature": 0.3  # è¾ƒä½çš„temperatureä»¥ä¿æŒä¸€è‡´æ€§
    }
    
    # é‡è¯•é€»è¾‘
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                # é‡è¯•å‰ç­‰å¾…ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥
                wait_time = min(2 ** attempt, 10)  # æœ€å¤šç­‰å¾…10ç§’
                print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡ï¼‰...", flush=True)
                time.sleep(wait_time)
            
            print(f"æ­£åœ¨ä½¿ç”¨AIç¿»è¯‘ï¼ˆé•¿åº¦: {len(text)} å­—ç¬¦ï¼‰{'[é‡è¯• ' + str(attempt + 1) + ']' if attempt > 0 else ''}...", flush=True)
            if attempt == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡å°è¯•æ—¶æ‰“å°æ¨¡å‹ä¿¡æ¯
                print(f"ä½¿ç”¨æ¨¡å‹: {translate_model}", flush=True)
            
            response = requests.post(
                translate_api_url,
                headers=headers,
                json=payload,
                timeout=Config.AI_TRANSLATE_TIMEOUT
            )
            response.raise_for_status()
            result = response.json()
            
            # æå–ç¿»è¯‘ç»“æœ
            if "choices" in result and len(result["choices"]) > 0:
                translated_text = result["choices"][0]["message"]["content"]
                
                # å¦‚æœä½¿ç”¨ think æ¨¡å‹ï¼Œè¿‡æ»¤æ‰æ€è€ƒè¿‡ç¨‹æ ‡ç­¾
                if "<think>" in translated_text and "</think>" in translated_text:
                    # ç§»é™¤ <think>...</think> æ ‡ç­¾åŠå…¶å†…å®¹
                    import re
                    translated_text = re.sub(r'<think>.*?</think>\s*', '', translated_text, flags=re.DOTALL)
                    print(f"âœ“ AIç¿»è¯‘å®Œæˆï¼ˆå·²è¿‡æ»¤æ€è€ƒè¿‡ç¨‹ï¼Œè¾“å‡ºé•¿åº¦: {len(translated_text)} å­—ç¬¦ï¼‰", flush=True)
                else:
                    print(f"âœ“ AIç¿»è¯‘å®Œæˆï¼ˆè¾“å‡ºé•¿åº¦: {len(translated_text)} å­—ç¬¦ï¼‰", flush=True)
                
                # æ¸…ç†HTMLæ ‡ç­¾å¹¶è½¬æ¢ä¸ºUnicode
                translated_text = clean_html_tags(translated_text)
                if '<sup>' in result["choices"][0]["message"]["content"] or '<sub>' in result["choices"][0]["message"]["content"]:
                    print(f"âœ“ å·²æ¸…ç†HTMLæ ‡ç­¾å¹¶è½¬æ¢ä¸ºUnicodeå­—ç¬¦", flush=True)
                
                # æ£€æŸ¥ç¿»è¯‘å®Œæ•´æ€§
                is_complete, remaining_words, original_words = check_translation_completeness(text, translated_text)
                if not is_complete:
                    print(f"âš ï¸ è­¦å‘Šï¼šç¿»è¯‘å¯èƒ½ä¸å®Œæ•´ï¼", flush=True)
                    print(f"   åŸæ–‡è‹±æ–‡å•è¯: {original_words}, è¯‘æ–‡æ®‹ç•™è‹±æ–‡å•è¯: {remaining_words}", flush=True)
                    print(f"   å»ºè®®ï¼šå¢åŠ  AI_TRANSLATE_MAX_TOKENS æˆ–åˆ†å—å¤„ç†", flush=True)
                else:
                    print(f"âœ“ ç¿»è¯‘å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡ï¼ˆæ®‹ç•™è‹±æ–‡å•è¯: {remaining_words}/{original_words}ï¼‰", flush=True)
                
                return translated_text.strip()
            else:
                print(f"âš ï¸ AIç¿»è¯‘å“åº”æ ¼å¼å¼‚å¸¸: {result}", flush=True)
                # å“åº”æ ¼å¼å¼‚å¸¸æ—¶ä¹Ÿé‡è¯•
                if attempt < max_retries - 1:
                    continue
                return text
                
        except requests.exceptions.Timeout:
            print(f"âš ï¸ AIç¿»è¯‘è¶…æ—¶", flush=True)
            if attempt < max_retries - 1:
                continue
            print(f"âš ï¸ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¿ç•™åŸæ–‡", flush=True)
            return text
        except requests.exceptions.ProxyError as e:
            print(f"âš ï¸ ä»£ç†è¿æ¥é”™è¯¯: {e}", flush=True)
            if attempt < max_retries - 1:
                continue
            print(f"âš ï¸ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¿ç•™åŸæ–‡", flush=True)
            return text
        except requests.exceptions.ConnectionError as e:
            print(f"âš ï¸ ç½‘ç»œè¿æ¥é”™è¯¯: {e}", flush=True)
            if attempt < max_retries - 1:
                continue
            print(f"âš ï¸ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¿ç•™åŸæ–‡", flush=True)
            return text
        except Exception as e:
            print(f"âš ï¸ AIç¿»è¯‘é”™è¯¯: {e}", flush=True)
            if attempt < max_retries - 1:
                continue
            print(f"âš ï¸ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¿ç•™åŸæ–‡", flush=True)
            return text
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›åŸæ–‡
    return text


def translate_with_deeplx(text, source_lang="EN", target_lang="ZH", max_retries=None):
    """ä½¿ç”¨DeepLX APIå¿«é€Ÿç¿»è¯‘æ–‡æœ¬ï¼ˆæ”¯æŒé‡è¯•ï¼‰"""
    from config import Config
    import time
    
    if not text or not text.strip():
        return text
    
    max_retries = max_retries or Config.DEEPLX_MAX_RETRIES
    
    payload = {
        "text": text,
        "source_lang": source_lang,
        "target_lang": target_lang
    }
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                wait_time = min(2 ** attempt, 5)
                print(f"â³ DeepLXé‡è¯•ç­‰å¾… {wait_time} ç§’ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡ï¼‰...", flush=True)
                time.sleep(wait_time)
            
            response = requests.post(Config.DEEPLX_API_URL, json=payload, timeout=Config.DEEPLX_TIMEOUT)
            response.raise_for_status()
            result = response.json()
            
            if result.get("code") == 200:
                translated = result.get("data", text)
                return translated
            else:
                print(f"âš ï¸ DeepLXç¿»è¯‘å¤±è´¥: {result}", flush=True)
                if attempt < max_retries - 1:
                    continue
                return text
                
        except requests.exceptions.Timeout:
            print(f"âš ï¸ DeepLXè¯·æ±‚è¶…æ—¶", flush=True)
            if attempt < max_retries - 1:
                continue
            return text
        except Exception as e:
            print(f"âš ï¸ DeepLXç¿»è¯‘é”™è¯¯: {e}", flush=True)
            if attempt < max_retries - 1:
                continue
            return text
    
    return text


def translate_markdown_content_with_ai(markdown_text, api_url=None, api_key=None, model=None):
    """ä½¿ç”¨AIç¿»è¯‘Markdownå†…å®¹ï¼Œæ™ºèƒ½å¤„ç†æ ¼å¼å’Œæ•°å­¦å…¬å¼"""
    # å…ˆæ¸…ç†æ•´ä¸ªæ–‡æœ¬çš„Unicodeå­—ç¬¦
    markdown_text = clean_unicode_characters(markdown_text, debug=False)
    
    # ä¼˜åŒ–åˆ†å—å¤§å°ï¼Œå‡å°‘å•æ¬¡è¯·æ±‚çš„è´Ÿæ‹…
    from config import Config
    max_chunk_size = Config.AI_TRANSLATE_CHUNK_SIZE  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„åˆ†å—å¤§å°
    
    if len(markdown_text) <= max_chunk_size:
        # å¦‚æœå†…å®¹ä¸é•¿ï¼Œä¸€æ¬¡æ€§ç¿»è¯‘
        print(f"å†…å®¹é€‚ä¸­ï¼ˆ{len(markdown_text)}å­—ç¬¦ï¼‰ï¼Œä¸€æ¬¡æ€§ç¿»è¯‘...", flush=True)
        translated_text = translate_with_ai(markdown_text, api_url=api_url, api_key=api_key, model=model)
        
        # éªŒè¯ç¿»è¯‘æ˜¯å¦å®Œæ•´
        if len(translated_text) < len(markdown_text) * 0.5:
            print(f"âš ï¸ è­¦å‘Šï¼šç¿»è¯‘è¾“å‡ºè¾ƒçŸ­ï¼ˆ{len(translated_text)}å­—ç¬¦ï¼‰ï¼Œå¯èƒ½ä¸å®Œæ•´", flush=True)
        
        return translated_text
    else:
        # å¦‚æœå†…å®¹è¾ƒé•¿ï¼ŒæŒ‰æ®µè½åˆ†å—ç¿»è¯‘
        print(f"å†…å®¹è¾ƒé•¿ï¼ˆ{len(markdown_text)}å­—ç¬¦ï¼‰ï¼Œåˆ†å—ç¿»è¯‘...", flush=True)
        print(f"ğŸ“Š ä½¿ç”¨åˆ†å—å¤§å°: {max_chunk_size} å­—ç¬¦", flush=True)
        
        # æŒ‰åŒæ¢è¡Œç¬¦åˆ†å‰²æ®µè½
        paragraphs = markdown_text.split('\n\n')
        translated_paragraphs = []
        
        current_chunk = ""
        chunk_count = 0
        total_chunks_estimate = len(markdown_text) // max_chunk_size + 1
        
        for i, para in enumerate(paragraphs):
            # å¦‚æœå•ä¸ªæ®µè½å°±è¶…è¿‡é™åˆ¶ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
            if len(para) > max_chunk_size:
                # å…ˆç¿»è¯‘å½“å‰ç´¯ç§¯çš„å—
                if current_chunk:
                    chunk_count += 1
                    print(f"ğŸ“ ç¿»è¯‘å— {chunk_count}/{total_chunks_estimate} (é•¿åº¦: {len(current_chunk)} å­—ç¬¦)...", flush=True)
                    translated_chunk = translate_with_ai(current_chunk, api_url=api_url, api_key=api_key, model=model)
                    translated_paragraphs.append(translated_chunk)
                    current_chunk = ""
                    time.sleep(0.5)  # å‡å°‘å»¶è¿Ÿ
                
                # å¯¹è¶…å¤§æ®µè½æŒ‰å¥å­åˆ†å‰²
                print(f"âš ï¸ å‘ç°è¶…å¤§æ®µè½ï¼ˆ{len(para)} å­—ç¬¦ï¼‰ï¼Œè¿›è¡ŒäºŒæ¬¡åˆ†å‰²...", flush=True)
                sentences = para.split('. ')
                temp_chunk = ""
                
                for sentence in sentences:
                    if len(temp_chunk) + len(sentence) + 2 <= max_chunk_size:
                        temp_chunk += sentence + '. ' if not sentence.endswith('.') else sentence + ' '
                    else:
                        if temp_chunk:
                            chunk_count += 1
                            print(f"ğŸ“ ç¿»è¯‘å— {chunk_count}/{total_chunks_estimate} (é•¿åº¦: {len(temp_chunk)} å­—ç¬¦)...", flush=True)
                            translated_chunk = translate_with_ai(temp_chunk.strip(), api_url=api_url, api_key=api_key, model=model)
                            translated_paragraphs.append(translated_chunk)
                            time.sleep(0.5)
                        temp_chunk = sentence + '. ' if not sentence.endswith('.') else sentence + ' '
                
                # ç¿»è¯‘å‰©ä½™çš„å¥å­
                if temp_chunk.strip():
                    chunk_count += 1
                    print(f"ğŸ“ ç¿»è¯‘å— {chunk_count}/{total_chunks_estimate} (é•¿åº¦: {len(temp_chunk)} å­—ç¬¦)...", flush=True)
                    translated_chunk = translate_with_ai(temp_chunk.strip(), api_url=api_url, api_key=api_key, model=model)
                    translated_paragraphs.append(translated_chunk)
                    time.sleep(0.5)
                
                continue
            
            # å¦‚æœå½“å‰å—åŠ ä¸Šè¿™ä¸ªæ®µè½ä¸è¶…è¿‡é™åˆ¶ï¼Œå°±ç´¯ç§¯
            if len(current_chunk) + len(para) + 2 <= max_chunk_size:
                if current_chunk:
                    current_chunk += "\n\n" + para
                else:
                    current_chunk = para
            else:
                # ç¿»è¯‘å½“å‰å—
                if current_chunk:
                    chunk_count += 1
                    print(f"ğŸ“ ç¿»è¯‘å— {chunk_count}/{total_chunks_estimate} (é•¿åº¦: {len(current_chunk)} å­—ç¬¦)...", flush=True)
                    translated_chunk = translate_with_ai(current_chunk, api_url=api_url, api_key=api_key, model=model)
                    translated_paragraphs.append(translated_chunk)
                    time.sleep(0.5)  # å‡å°‘å»¶è¿Ÿ
                
                # å¼€å§‹æ–°å—
                current_chunk = para
        
        # ç¿»è¯‘æœ€åä¸€å—
        if current_chunk:
            chunk_count += 1
            print(f"ğŸ“ ç¿»è¯‘å— {chunk_count}/{total_chunks_estimate} (é•¿åº¦: {len(current_chunk)} å­—ç¬¦)...", flush=True)
            translated_chunk = translate_with_ai(current_chunk, api_url=api_url, api_key=api_key, model=model)
            translated_paragraphs.append(translated_chunk)
        
        # åˆå¹¶æ‰€æœ‰ç¿»è¯‘ç»“æœ
        result = "\n\n".join(translated_paragraphs)
        print(f"âœ… å®Œæˆåˆ†å—ç¿»è¯‘ï¼Œå…± {chunk_count} å—", flush=True)
        return result


def fix_formulas_with_ai(text, api_url=None, api_key=None, model=None):
    """ä½¿ç”¨AI APIä¸“é—¨ä¿®æ­£ç¿»è¯‘åæ–‡æœ¬ä¸­çš„æ•°å­¦å…¬å¼"""
    from config import Config
    import time
    import re
    
    if not text or not text.strip():
        return text
    
    # ç¬¬ä¸€æ­¥ï¼šä¿æŠ¤å›¾ç‰‡æ ‡è®°ï¼Œé¿å…è¢«AIå¤„ç†
    image_pattern = r'!\[([^\]]*)\]\(([^\)]+)\)'
    images = []
    
    def save_image(match):
        placeholder = f"<<<IMAGE_PLACEHOLDER_{len(images)}>>>"
        images.append(match.group(0))
        return placeholder
    
    # æ›¿æ¢å›¾ç‰‡ä¸ºå ä½ç¬¦
    text_without_images = re.sub(image_pattern, save_image, text)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„å…¬å¼éœ€è¦ä¿®æ­£ï¼ˆå¦‚æœæ²¡æœ‰ï¼Œç›´æ¥è¿”å›ï¼‰
    has_formulas = bool(re.search(r'[\$\\]', text_without_images))
    if not has_formulas and not re.search(r'<su[bp]>', text_without_images):
        print(f"âœ“ æœªæ£€æµ‹åˆ°éœ€è¦ä¿®æ­£çš„å…¬å¼ï¼Œè·³è¿‡AIä¿®æ­£", flush=True)
        return text  # ç›´æ¥è¿”å›åŸæ–‡ï¼Œä¿ç•™å›¾ç‰‡
    
    # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
    translate_api_url = api_url or Config.AI_TRANSLATE_API_URL
    translate_api_key = api_key or Config.AI_TRANSLATE_API_KEY
    translate_model = model or Config.AI_TRANSLATE_MODEL
    max_retries = Config.AI_TRANSLATE_MAX_RETRIES
    
    # å¤„ç†API URL
    if translate_api_url and not translate_api_url.endswith('/chat/completions'):
        translate_api_url = translate_api_url.rstrip('/')
        if not translate_api_url.endswith('/v1'):
            translate_api_url += '/v1'
        translate_api_url += '/chat/completions'
    
    # æåº¦ç®€åŒ–å’Œä¸¥æ ¼çš„ç³»ç»Ÿæç¤º
    system_prompt = """ä½ æ˜¯å…¬å¼ä¿®æ­£ä¸“å®¶ã€‚ä½ æ”¶åˆ°çš„æ˜¯å·²ç»ç¿»è¯‘å¥½çš„ä¸­æ–‡æ–‡æœ¬ï¼Œé‡Œé¢å¯èƒ½æœ‰æ˜¾ç¤ºå¼‚å¸¸çš„æ•°å­¦å…¬å¼ã€‚

**ä½ çš„å”¯ä¸€ä»»åŠ¡**ï¼šä¿®æ­£å…¬å¼æ˜¾ç¤ºï¼Œå…¶ä»–å†…å®¹ä¸€å­—ä¸æ”¹ã€‚

**ä¿®æ­£è§„åˆ™**ï¼š
1. LaTeXå…¬å¼è½¬Unicodeï¼š$^{13}C$ â†’ Â¹Â³Cï¼Œ$O_2$ â†’ Oâ‚‚
2. ç§»é™¤HTMLæ ‡ç­¾ï¼š<sup>13</sup> â†’ Â¹Â³
3. ç§»é™¤æ–¹æ¡†å­—ç¬¦ â–¡
4. æ•°å­¦ç¬¦å·ï¼š$\\sim$ â†’ âˆ¼ï¼Œ$\\pm$ â†’ Â±

**ä¸¥æ ¼ç¦æ­¢**ï¼š
âŒ ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–è¯´æ˜
âŒ ä¸è¦è¯¢é—®ç”¨æˆ·ä»»ä½•é—®é¢˜
âŒ ä¸è¦ç”Ÿæˆæ–°å†…å®¹
âŒ ä¸è¦æ”¹å˜ç¿»è¯‘
âŒ å¦‚æœæ–‡æœ¬ä¸­æœ‰å›¾ç‰‡å ä½ç¬¦ï¼ˆ<<<IMAGE_PLACEHOLDER_X>>>ï¼‰ï¼Œå¿…é¡»åŸæ ·ä¿ç•™

**è¾“å‡ºè¦æ±‚**ï¼š
åªè¿”å›ä¿®æ­£åçš„æ–‡æœ¬ï¼Œä¿æŒæ‰€æœ‰å†…å®¹ã€æ®µè½ã€æ ¼å¼å®Œå…¨ä¸€è‡´ã€‚"""

    headers = {
        "Authorization": f"Bearer {translate_api_key}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": translate_model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¯·ä¿®æ­£ä»¥ä¸‹æ–‡æœ¬ä¸­çš„æ•°å­¦å…¬å¼ï¼š\n\n{text_without_images}"}
        ],
        "max_tokens": Config.AI_TRANSLATE_MAX_TOKENS,
        "temperature": 0.0  # é›¶temperatureï¼Œä¿æŒå®Œå…¨ä¸€è‡´æ€§
    }
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                wait_time = min(2 ** attempt, 10)
                print(f"â³ å…¬å¼ä¿®æ­£é‡è¯•ç­‰å¾… {wait_time} ç§’ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡ï¼‰...", flush=True)
                time.sleep(wait_time)
            
            print(f"ğŸ”§ æ­£åœ¨ä¿®æ­£æ•°å­¦å…¬å¼ï¼ˆé•¿åº¦: {len(text_without_images)} å­—ç¬¦ï¼‰{'[é‡è¯• ' + str(attempt + 1) + ']' if attempt > 0 else ''}...", flush=True)
            
            response = requests.post(
                translate_api_url,
                headers=headers,
                json=payload,
                timeout=Config.AI_TRANSLATE_TIMEOUT
            )
            response.raise_for_status()
            result = response.json()
            
            if "choices" in result and len(result["choices"]) > 0:
                fixed_text = result["choices"][0]["message"]["content"]
                
                # è¿‡æ»¤æ€è€ƒæ ‡ç­¾
                if "<think>" in fixed_text and "</think>" in fixed_text:
                    fixed_text = re.sub(r'<think>.*?</think>\s*', '', fixed_text, flags=re.DOTALL)
                
                # æ¸…ç†HTMLæ ‡ç­¾
                fixed_text = clean_html_tags(fixed_text)
                
                # éªŒè¯è¾“å‡ºé•¿åº¦ï¼Œé¿å…AIç”Ÿæˆæ— å…³å†…å®¹
                original_len = len(text_without_images)
                output_len = len(fixed_text)
                
                # å¦‚æœè¾“å‡ºé•¿åº¦å·®å¼‚è¶…è¿‡50%ï¼Œå¯èƒ½æ˜¯AIç”Ÿæˆäº†æ— å…³å†…å®¹
                if abs(output_len - original_len) > original_len * 0.5:
                    print(f"âš ï¸ è­¦å‘Šï¼šAIè¾“å‡ºé•¿åº¦å¼‚å¸¸ï¼ˆåŸæ–‡:{original_len}, è¾“å‡º:{output_len}ï¼‰ï¼Œä½¿ç”¨åŸæ–‡", flush=True)
                    fixed_text = text_without_images
                
                # æ£€æŸ¥AIæ˜¯å¦è¿”å›äº†æé—®æˆ–è§£é‡Š
                if any(phrase in fixed_text[:200] for phrase in ['I need', 'I can see', 'Could you', 'Please provide', 'æˆ‘éœ€è¦', 'è¯·æä¾›']):
                    print(f"âš ï¸ è­¦å‘Šï¼šAIè¿”å›äº†æé—®è€Œéä¿®æ­£ç»“æœï¼Œä½¿ç”¨åŸæ–‡", flush=True)
                    fixed_text = text_without_images
                
                # æ¢å¤å›¾ç‰‡å ä½ç¬¦ä¸ºåŸå§‹å›¾ç‰‡
                for i, img in enumerate(images):
                    placeholder = f"<<<IMAGE_PLACEHOLDER_{i}>>>"
                    fixed_text = fixed_text.replace(placeholder, img)
                
                print(f"âœ“ å…¬å¼ä¿®æ­£å®Œæˆï¼ˆè¾“å‡ºé•¿åº¦: {len(fixed_text)} å­—ç¬¦ï¼‰", flush=True)
                print(f"âœ“ å·²æ¢å¤ {len(images)} å¼ å›¾ç‰‡", flush=True)
                
                return fixed_text.strip()
            else:
                print(f"âš ï¸ å…¬å¼ä¿®æ­£å“åº”æ ¼å¼å¼‚å¸¸", flush=True)
                if attempt < max_retries - 1:
                    continue
                return text
                
        except Exception as e:
            print(f"âš ï¸ å…¬å¼ä¿®æ­£é”™è¯¯: {e}", flush=True)
            if attempt < max_retries - 1:
                continue
            return text
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›åŸæ–‡ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
    return text


def translate_markdown_hybrid(markdown_text, api_url=None, api_key=None, model=None):
    """
    æ··åˆç¿»è¯‘æ¨¡å¼ï¼ˆä¸‰æ­¥èµ°ç­–ç•¥ï¼‰ï¼š
    1. ä½¿ç”¨MinerUæå–å†…å®¹ï¼ˆå·²å®Œæˆï¼‰
    2. ä½¿ç”¨DeepLXå¿«é€Ÿç¿»è¯‘
    3. ä½¿ç”¨AIä¿®æ­£æ•°å­¦å…¬å¼
    """
    from config import Config
    import time
    
    print("\n" + "=" * 60)
    print("ğŸš€ ä½¿ç”¨æ··åˆç¿»è¯‘æ¨¡å¼ï¼ˆDeepLX + AIå…¬å¼ä¿®æ­£ï¼‰")
    print("=" * 60)
    
    # ç¬¬ä¸€æ­¥ï¼šæ¸…ç†Unicodeå­—ç¬¦
    print("\nğŸ“‹ æ­¥éª¤ 1/3: æ¸…ç†æ–‡æœ¬...")
    markdown_text = clean_unicode_characters(markdown_text, debug=False)
    print(f"âœ“ æ–‡æœ¬æ¸…ç†å®Œæˆï¼ˆé•¿åº¦: {len(markdown_text)} å­—ç¬¦ï¼‰")
    
    # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨DeepLXå¿«é€Ÿç¿»è¯‘
    print("\nâš¡ æ­¥éª¤ 2/3: DeepLXå¿«é€Ÿç¿»è¯‘...")
    
    # æŒ‰æ®µè½åˆ†å—ç¿»è¯‘ï¼ˆDeepLXå¯¹é•¿æ–‡æœ¬æ”¯æŒè¾ƒå¥½ï¼Œå¯ä»¥ç”¨è¾ƒå¤§çš„å—ï¼‰
    max_chunk_size = 5000  # DeepLXå¯ä»¥å¤„ç†æ›´å¤§çš„å—
    paragraphs = markdown_text.split('\n\n')
    translated_paragraphs = []
    
    current_chunk = ""
    chunk_count = 0
    total_paragraphs = len(paragraphs)
    image_count = 0
    
    start_time = time.time()
    
    for i, para in enumerate(paragraphs):
        # è·³è¿‡å›¾ç‰‡æ ‡è®°ï¼ˆå®Œæ•´ä¿ç•™ï¼Œä¸ç¿»è¯‘ï¼‰
        if para.strip().startswith('![') or para.strip().startswith('<img'):
            translated_paragraphs.append(para)
            image_count += 1
            print(f"  ğŸ–¼ï¸ ä¿ç•™å›¾ç‰‡ {image_count}", flush=True)
            continue
        
        # ç´¯ç§¯æ®µè½åˆ°å½“å‰å—
        if len(current_chunk) + len(para) + 2 <= max_chunk_size:
            if current_chunk:
                current_chunk += "\n\n" + para
            else:
                current_chunk = para
        else:
            # ç¿»è¯‘å½“å‰å—
            if current_chunk:
                chunk_count += 1
                print(f"  ğŸ“ ç¿»è¯‘å— {chunk_count} (é•¿åº¦: {len(current_chunk)} å­—ç¬¦, è¿›åº¦: {i}/{total_paragraphs} æ®µè½)...", flush=True)
                translated_chunk = translate_with_deeplx(current_chunk)
                translated_paragraphs.append(translated_chunk)
                time.sleep(Config.DEEPLX_RATE_LIMIT)
            
            # å¼€å§‹æ–°å—
            current_chunk = para
    
    # ç¿»è¯‘æœ€åä¸€å—
    if current_chunk:
        chunk_count += 1
        print(f"  ğŸ“ ç¿»è¯‘å— {chunk_count} (é•¿åº¦: {len(current_chunk)} å­—ç¬¦)...", flush=True)
        translated_chunk = translate_with_deeplx(current_chunk)
        translated_paragraphs.append(translated_chunk)
    
    deeplx_result = "\n\n".join(translated_paragraphs)
    deeplx_time = time.time() - start_time
    
    print(f"âœ“ DeepLXç¿»è¯‘å®Œæˆï¼å…± {chunk_count} å—ï¼Œè€—æ—¶ {deeplx_time:.1f} ç§’")
    print(f"  åŸæ–‡é•¿åº¦: {len(markdown_text)} å­—ç¬¦")
    print(f"  è¯‘æ–‡é•¿åº¦: {len(deeplx_result)} å­—ç¬¦")
    print(f"  ä¿ç•™å›¾ç‰‡: {image_count} å¼ ")
    
    # ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨AIä¿®æ­£æ•°å­¦å…¬å¼
    print("\nğŸ”§ æ­¥éª¤ 3/3: AIä¿®æ­£æ•°å­¦å…¬å¼...")
    
    # åˆ†å—ä¿®æ­£ï¼ˆé¿å…è¶…é•¿æ–‡æœ¬ï¼‰
    max_fix_chunk_size = 4000
    
    if len(deeplx_result) <= max_fix_chunk_size:
        print(f"  æ–‡æœ¬é€‚ä¸­ï¼Œä¸€æ¬¡æ€§ä¿®æ­£...")
        final_result = fix_formulas_with_ai(deeplx_result, api_url=api_url, api_key=api_key, model=model)
    else:
        print(f"  æ–‡æœ¬è¾ƒé•¿ï¼Œåˆ†å—ä¿®æ­£...")
        fix_paragraphs = deeplx_result.split('\n\n')
        fixed_results = []
        
        current_fix_chunk = ""
        fix_chunk_count = 0
        
        for para in fix_paragraphs:
            if len(current_fix_chunk) + len(para) + 2 <= max_fix_chunk_size:
                if current_fix_chunk:
                    current_fix_chunk += "\n\n" + para
                else:
                    current_fix_chunk = para
            else:
                if current_fix_chunk:
                    fix_chunk_count += 1
                    print(f"  ğŸ”§ ä¿®æ­£å— {fix_chunk_count} (é•¿åº¦: {len(current_fix_chunk)} å­—ç¬¦)...", flush=True)
                    fixed_chunk = fix_formulas_with_ai(current_fix_chunk, api_url=api_url, api_key=api_key, model=model)
                    fixed_results.append(fixed_chunk)
                    time.sleep(0.5)
                
                current_fix_chunk = para
        
        # ä¿®æ­£æœ€åä¸€å—
        if current_fix_chunk:
            fix_chunk_count += 1
            print(f"  ğŸ”§ ä¿®æ­£å— {fix_chunk_count} (é•¿åº¦: {len(current_fix_chunk)} å­—ç¬¦)...", flush=True)
            fixed_chunk = fix_formulas_with_ai(current_fix_chunk, api_url=api_url, api_key=api_key, model=model)
            fixed_results.append(fixed_chunk)
        
        final_result = "\n\n".join(fixed_results)
        print(f"âœ“ å…¬å¼ä¿®æ­£å®Œæˆï¼å…±ä¿®æ­£ {fix_chunk_count} å—")
    
    total_time = time.time() - start_time
    
    print("\n" + "=" * 60)
    print(f"ğŸ‰ æ··åˆç¿»è¯‘å®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f} ç§’")
    print(f"   DeepLXç¿»è¯‘: {deeplx_time:.1f} ç§’ ({deeplx_time/total_time*100:.1f}%)")
    print(f"   AIå…¬å¼ä¿®æ­£: {total_time - deeplx_time:.1f} ç§’ ({(total_time - deeplx_time)/total_time*100:.1f}%)")
    print("=" * 60 + "\n")
    
    return final_result


def translate_markdown_content(markdown_text):
    """ç¿»è¯‘Markdownå†…å®¹ï¼Œä¿ç•™æ ¼å¼ï¼ˆçº¯DeepLXæ¨¡å¼ï¼‰"""
    # å…ˆæ¸…ç†æ•´ä¸ªæ–‡æœ¬çš„Unicodeå­—ç¬¦
    markdown_text = clean_unicode_characters(markdown_text, debug=False)
    
    lines = markdown_text.split('\n')
    translated_lines = []
    
    for line in lines:
        # è·³è¿‡ç©ºè¡Œ
        if not line.strip():
            translated_lines.append(line)
            continue
        
        # è·³è¿‡ä»£ç å—æ ‡è®°
        if line.strip().startswith('```'):
            translated_lines.append(line)
            continue
        
        # è·³è¿‡å›¾ç‰‡æ ‡è®°ï¼ˆä¿ç•™åŸæ ·ï¼‰
        if line.strip().startswith('![') or line.strip().startswith('<img'):
            translated_lines.append(line)
            continue
        
        # ç¿»è¯‘å…¶ä»–å†…å®¹
        translated_line = translate_with_deeplx(line)
        # ç¿»è¯‘åçš„å†…å®¹ä¹Ÿæ¸…ç†ä¸€ä¸‹
        translated_line = clean_unicode_characters(translated_line, debug=False)
        translated_lines.append(translated_line)
        time.sleep(0.5)  # é¿å…APIé™æµ
    
    return '\n'.join(translated_lines)


def check_translation_completeness(original, translated):
    """æ£€æŸ¥ç¿»è¯‘æ˜¯å¦å®Œæ•´"""
    import re
    
    # ç»Ÿè®¡åŸæ–‡ä¸­çš„è‹±æ–‡å•è¯æ•°ï¼ˆç²—ç•¥ä¼°è®¡ï¼‰
    original_words = len(re.findall(r'\b[a-zA-Z]+\b', original))
    
    # ç»Ÿè®¡ç¿»è¯‘åå‰©ä½™çš„è‹±æ–‡å•è¯æ•°
    translated_words = len(re.findall(r'\b[a-zA-Z]{4,}\b', translated))  # 4ä¸ªå­—æ¯ä»¥ä¸Šçš„è‹±æ–‡å•è¯
    
    # å¦‚æœç¿»è¯‘åè¿˜æœ‰å¤§é‡è‹±æ–‡å•è¯ï¼ˆè¶…è¿‡åŸæ–‡çš„30%ï¼‰ï¼Œå¯èƒ½ä¸å®Œæ•´
    if original_words > 0 and translated_words > original_words * 0.3:
        return False, translated_words, original_words
    
    return True, translated_words, original_words


def clean_html_tags(text):
    """æ¸…ç†HTMLæ ‡ç­¾å¹¶è½¬æ¢ä¸ºUnicodeå­—ç¬¦"""
    import re
    
    # ä¸Šæ ‡æ•°å­—æ˜ å°„
    superscripts = {
        '0': 'â°', '1': 'Â¹', '2': 'Â²', '3': 'Â³', '4': 'â´',
        '5': 'âµ', '6': 'â¶', '7': 'â·', '8': 'â¸', '9': 'â¹',
        '+': 'âº', '-': 'â»', '=': 'â¼', '(': 'â½', ')': 'â¾',
        ',': ','  # é€—å·ä¿æŒä¸å˜
    }
    
    # ä¸‹æ ‡æ•°å­—æ˜ å°„
    subscripts = {
        '0': 'â‚€', '1': 'â‚', '2': 'â‚‚', '3': 'â‚ƒ', '4': 'â‚„',
        '5': 'â‚…', '6': 'â‚†', '7': 'â‚‡', '8': 'â‚ˆ', '9': 'â‚‰',
        '+': 'â‚Š', '-': 'â‚‹', '=': 'â‚Œ', '(': 'â‚', ')': 'â‚'
    }
    
    # å¤„ç† <sup>...</sup> æ ‡ç­¾
    def replace_sup(match):
        content = match.group(1)
        result = ''
        for char in content:
            result += superscripts.get(char, char)
        return result
    
    text = re.sub(r'<sup>([^<]+)</sup>', replace_sup, text, flags=re.IGNORECASE)
    
    # å¤„ç† <sub>...</sub> æ ‡ç­¾
    def replace_sub(match):
        content = match.group(1)
        result = ''
        for char in content:
            result += subscripts.get(char, char)
        return result
    
    text = re.sub(r'<sub>([^<]+)</sub>', replace_sub, text, flags=re.IGNORECASE)
    
    # ç§»é™¤å…¶ä»–å¸¸è§çš„HTMLæ ‡ç­¾ä½†ä¿ç•™å†…å®¹
    text = re.sub(r'</?b>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'</?i>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'</?strong>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'</?em>', '', text, flags=re.IGNORECASE)
    
    return text


def clean_unicode_characters(text, debug=False):
    """æ¸…ç†æ–‡æœ¬ä¸­æ— æ³•æ˜¾ç¤ºçš„Unicodeå­—ç¬¦"""
    from config import Config
    import unicodedata
    
    original_text = text
    
    # ç¬¬ä¸€æ­¥ï¼šåº”ç”¨é…ç½®ä¸­çš„å­—ç¬¦æ›¿æ¢è§„åˆ™
    for old_char, new_char in Config.UNICODE_REPLACEMENTS.items():
        text = text.replace(old_char, new_char)
    
    # ç¬¬äºŒæ­¥ï¼šæŸ¥æ‰¾å¹¶å¤„ç†å‰©ä½™çš„é—®é¢˜å­—ç¬¦
    cleaned_text = []
    removed_chars = set()
    
    for char in text:
        code_point = ord(char)
        
        # REPLACEMENT CHARACTER (U+FFFD) æ˜¯æ˜¾ç¤ºæ–¹æ¡†çš„ä¸»è¦åŸå› 
        if code_point == 0xFFFD:
            removed_chars.add((char, code_point, 'REPLACEMENT CHARACTER'))
            continue
        
        # ç§æœ‰ä½¿ç”¨åŒºå­—ç¬¦é€šå¸¸æ— æ³•æ˜¾ç¤º
        if (0xE000 <= code_point <= 0xF8FF or  # ç§æœ‰ä½¿ç”¨åŒº
            0xF0000 <= code_point <= 0xFFFFD or  # è¡¥å……ç§æœ‰ä½¿ç”¨åŒº-A
            0x100000 <= code_point <= 0x10FFFD):  # è¡¥å……ç§æœ‰ä½¿ç”¨åŒº-B
            try:
                char_name = unicodedata.name(char, f'PRIVATE_USE_U+{code_point:04X}')
            except:
                char_name = f'PRIVATE_USE_U+{code_point:04X}'
            removed_chars.add((char, code_point, char_name))
            continue
        
        # æ§åˆ¶å­—ç¬¦ï¼ˆé™¤äº†å¸¸è§çš„æ¢è¡Œã€åˆ¶è¡¨ç¬¦ç­‰ï¼‰
        if (0x00 <= code_point <= 0x1F and 
            code_point not in [0x09, 0x0A, 0x0D]):  # ä¿ç•™tab, LF, CR
            removed_chars.add((char, code_point, 'CONTROL_CHARACTER'))
            continue
        
        # ä¿ç•™å…¶ä»–å­—ç¬¦
        cleaned_text.append(char)
    
    result = ''.join(cleaned_text)
    
    # æ‰“å°è°ƒè¯•ä¿¡æ¯
    if debug:
        if removed_chars:
            print(f"âš ï¸ æ¸…ç†æ–‡æœ¬æ—¶ç§»é™¤äº† {len(removed_chars)} ç§é—®é¢˜å­—ç¬¦:", flush=True)
            for char, code, name in list(removed_chars)[:20]:  # æœ€å¤šæ˜¾ç¤º20ä¸ª
                print(f"  '{char}' | U+{code:04X} | {name}", flush=True)
        else:
            print("âœ“ æ²¡æœ‰å‘ç°éœ€è¦ç§»é™¤çš„é—®é¢˜å­—ç¬¦", flush=True)
        
        # ç»Ÿè®¡è¢«æ›¿æ¢çš„å­—ç¬¦
        replaced_count = 0
        for old_char in Config.UNICODE_REPLACEMENTS.keys():
            if old_char in original_text:
                replaced_count += original_text.count(old_char)
        if replaced_count > 0:
            print(f"âœ“ æ›¿æ¢äº† {replaced_count} ä¸ªç‰¹æ®ŠUnicodeå­—ç¬¦", flush=True)
    
    # å¦‚æœæ–‡æœ¬æœ‰å˜åŒ–ï¼Œæ‰“å°ç®€è¦ä¿¡æ¯
    elif result != original_text:
        print(f"âœ“ æ¸…ç†äº†æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦", flush=True)
    
    return result


def convert_latex_to_unicode(text):
    """å°†å¸¸è§çš„ LaTeX æ•°å­¦ç¬¦å·è½¬æ¢ä¸º Unicode"""
    original_text = text  # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºè°ƒè¯•
    
    # ä¸Šæ ‡æ•°å­—æ˜ å°„
    superscripts = {
        '0': 'â°', '1': 'Â¹', '2': 'Â²', '3': 'Â³', '4': 'â´',
        '5': 'âµ', '6': 'â¶', '7': 'â·', '8': 'â¸', '9': 'â¹',
        '+': 'âº', '-': 'â»', '=': 'â¼', '(': 'â½', ')': 'â¾'
    }
    
    # ä¸‹æ ‡æ•°å­—æ˜ å°„
    subscripts = {
        '0': 'â‚€', '1': 'â‚', '2': 'â‚‚', '3': 'â‚ƒ', '4': 'â‚„',
        '5': 'â‚…', '6': 'â‚†', '7': 'â‚‡', '8': 'â‚ˆ', '9': 'â‚‰',
        '+': 'â‚Š', '-': 'â‚‹', '=': 'â‚Œ', '(': 'â‚', ')': 'â‚'
    }
    
    # å¸Œè…Šå­—æ¯æ˜ å°„
    greek_letters = {
        r'\alpha': 'Î±', r'\beta': 'Î²', r'\gamma': 'Î³', r'\delta': 'Î´',
        r'\Delta': 'Î”', r'\epsilon': 'Îµ', r'\zeta': 'Î¶', r'\eta': 'Î·',
        r'\theta': 'Î¸', r'\Theta': 'Î˜', r'\lambda': 'Î»', r'\Lambda': 'Î›',
        r'\mu': 'Î¼', r'\nu': 'Î½', r'\xi': 'Î¾', r'\pi': 'Ï€', r'\Pi': 'Î ',
        r'\rho': 'Ï', r'\sigma': 'Ïƒ', r'\Sigma': 'Î£', r'\tau': 'Ï„',
        r'\phi': 'Ï†', r'\Phi': 'Î¦', r'\chi': 'Ï‡', r'\psi': 'Ïˆ', r'\Psi': 'Î¨',
        r'\omega': 'Ï‰', r'\Omega': 'Î©'
    }
    
    # å…¶ä»–å¸¸ç”¨ç¬¦å·
    symbols = {
        r'\sim': 'âˆ¼', r'\approx': 'â‰ˆ', r'\pm': 'Â±', r'\times': 'Ã—',
        r'\div': 'Ã·', r'\leq': 'â‰¤', r'\geq': 'â‰¥', r'\neq': 'â‰ ',
        r'\infty': 'âˆ', r'\sum': 'âˆ‘', r'\prod': 'âˆ', r'\int': 'âˆ«',
        r'\partial': 'âˆ‚', r'\nabla': 'âˆ‡', r'\cdot': 'Â·'
    }
    
    # é¦–å…ˆå¤„ç†å¸Œè…Šå­—æ¯å’Œç¬¦å·
    for latex, unicode_char in greek_letters.items():
        text = text.replace(latex, unicode_char)
    for latex, unicode_char in symbols.items():
        text = text.replace(latex, unicode_char)
    
    # å¤„ç†ä¸Šæ ‡ ^{...}
    def replace_superscript(match):
        content = match.group(1)
        result = ''
        for char in content:
            result += superscripts.get(char, char)
        return result
    
    text = re.sub(r'\^{([^}]+)}', replace_superscript, text)
    
    # å¤„ç†ç®€å•ä¸Šæ ‡ ^x
    def replace_simple_superscript(match):
        char = match.group(1)
        return superscripts.get(char, '^' + char)
    
    text = re.sub(r'\^([0-9+-])', replace_simple_superscript, text)
    
    # å¤„ç†ä¸‹æ ‡ _{...}
    def replace_subscript(match):
        content = match.group(1)
        result = ''
        for char in content:
            result += subscripts.get(char, char)
        return result
    
    text = re.sub(r'_{([^}]+)}', replace_subscript, text)
    
    # å¤„ç†ç®€å•ä¸‹æ ‡ _x
    def replace_simple_subscript(match):
        char = match.group(1)
        return subscripts.get(char, '_' + char)
    
    text = re.sub(r'_([0-9+-])', replace_simple_subscript, text)
    
    # å¤„ç† \mathrm{...}
    text = re.sub(r'\\mathrm{([^}]+)}', r'\1', text)
    
    # ç§»é™¤å‰©ä½™çš„åæ–œæ å‘½ä»¤
    text = re.sub(r'\\[a-zA-Z]+', '', text)
    
    # ç§»é™¤å¤šä½™çš„èŠ±æ‹¬å·
    text = text.replace('{', '').replace('}', '')
    
    # æ¸…ç†å¯èƒ½æ®‹ç•™çš„é—®é¢˜Unicodeå­—ç¬¦
    text = clean_unicode_characters(text, debug=False)
    
    # å¦‚æœè½¬æ¢æœ‰å˜åŒ–ï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯
    if text != original_text:
        print(f"âœ“ å…¬å¼è½¬æ¢: '{original_text}' â†’ '{text}'")
    
    return text


def markdown_to_pdf(markdown_text, output_path):
    """å°†Markdownè½¬æ¢ä¸ºPDF"""
    import sys
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Image
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_JUSTIFY
    from reportlab.pdfbase.cidfonts import UnicodeCIDFont
    
    # åœ¨å¼€å§‹å¤„ç†å‰ï¼Œå…ˆè¿›è¡Œä¸€æ¬¡å®Œæ•´çš„å­—ç¬¦æ¸…ç†ï¼ˆå¯ç”¨è°ƒè¯•ï¼‰
    print("\n" + "="*50, flush=True)
    print("å¼€å§‹æ¸…ç†Markdownæ–‡æœ¬ä¸­çš„é—®é¢˜å­—ç¬¦...", flush=True)
    print(f"åŸå§‹æ–‡æœ¬é•¿åº¦: {len(markdown_text)}", flush=True)
    print("="*50, flush=True)
    sys.stdout.flush()
    
    markdown_text = clean_unicode_characters(markdown_text, debug=True)
    
    print(f"æ¸…ç†åæ–‡æœ¬é•¿åº¦: {len(markdown_text)}", flush=True)
    print("="*50 + "\n", flush=True)
    sys.stdout.flush()
    
    # åˆ›å»ºPDFæ–‡æ¡£
    doc = SimpleDocTemplate(output_path, pagesize=A4,
                           rightMargin=72, leftMargin=72,
                           topMargin=72, bottomMargin=18)
    
    story = []
    styles = getSampleStyleSheet()
    
    # æ³¨å†Œå­—ä½“ - ä¼˜å…ˆä½¿ç”¨æ”¯æŒå®Œæ•´ Unicode çš„å­—ä½“
    font_registered = False

    # å…è®¸é€šè¿‡ç¯å¢ƒ/é…ç½®æˆ–é¡¹ç›®å†… fonts ç›®å½•æŒ‚è½½å­—ä½“ï¼Œä»¥ä¾¿åœ¨ç²¾ç®€å®¹å™¨ï¼ˆå¦‚ Zeaburï¼‰ä¸­é¿å…ä¹±ç 
    local_font_dir = os.path.join(os.path.dirname(__file__), 'fonts')
    font_paths = []

    # ç”¨æˆ·è‡ªå®šä¹‰è·¯å¾„ä¼˜å…ˆï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡ PDF_FONT_PATH è¦†ç›– Config.PDF_FONT_PATHï¼‰
    custom_font_path = os.environ.get('PDF_FONT_PATH') or Config.PDF_FONT_PATH
    if custom_font_path:
        font_paths.append(custom_font_path)
        print(f"è‡ªå®šä¹‰å­—ä½“è·¯å¾„: {custom_font_path}", flush=True)

    # é¡¹ç›®å†…ç½®/æŒ‚è½½å­—ä½“ç›®å½•ï¼ˆéœ€è¦è‡ªè¡Œæ”¾ç½®å­—ä½“æ–‡ä»¶ï¼‰
    # æ³¨æ„ï¼šReportLab åªæ”¯æŒ TrueType æ ¼å¼(.ttf)ï¼Œä¸æ”¯æŒ PostScript outlines (.otf CFF)
    if os.path.isdir(local_font_dir):
        for candidate in [
            'Arial-Unicode.ttf',  # æœ¬åœ°å¼€å‘ç”¨çš„ç¬¦å·é“¾æ¥
            'NotoSansCJKsc-Regular.ttf',  # å®Œæ•´ç‰ˆ TrueType (æ¨è)
            'NotoSansSC-Regular.ttf',  # Google Fonts ç‰ˆæœ¬ TrueType
            'SourceHanSansCN-Regular.ttf',  # æ€æºé»‘ä½“ TrueType
            'DejaVuSans.ttf', 'DejaVuSansMono.ttf'
        ]:
            font_paths.append(os.path.join(local_font_dir, candidate))

    # ç³»ç»Ÿå¸¸è§å­—ä½“ - ä¼˜å…ˆçº§ï¼šè¦†ç›– Unicode çš„å­—ä½“ä¼˜å…ˆ
    font_paths.extend([
        # macOS å­—ä½“ - Arial Unicode MS æ”¯æŒæœ€å®Œæ•´çš„ Unicode
        '/System/Library/Fonts/Supplemental/Arial Unicode.ttf',
        '/Library/Fonts/Arial Unicode.ttf',
        # macOS å…¶ä»–æ”¯æŒå¹¿æ³› Unicode çš„å­—ä½“
        '/System/Library/Fonts/Apple Symbols.ttf',
        '/System/Library/Fonts/Helvetica.ttc',
        # ç„¶åæ˜¯ä¸­æ–‡å­—ä½“
        '/System/Library/Fonts/PingFang.ttc',
        '/System/Library/Fonts/STHeiti Light.ttc',
        # Linux å­—ä½“
        '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
        '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf',
        '/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf',
        '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
        '/usr/share/fonts/opentype/noto/NotoSansCJKsc-Regular.otf',
        # Windows å­—ä½“
        'C:\\Windows\\Fonts\\Arial.ttf',
        'C:\\Windows\\Fonts\\arialuni.ttf',
        'C:\\Windows\\Fonts\\simhei.ttf',
        'C:\\Windows\\Fonts\\simsun.ttc',
    ])

    for font_path in font_paths:
        try:
            if os.path.exists(font_path):
                pdfmetrics.registerFont(TTFont('UnicodeFont', font_path))
                font_registered = True
                print(f"âœ“ æˆåŠŸæ³¨å†Œå­—ä½“: {font_path}")
                font_name = 'UnicodeFont'
                break
        except Exception as e:
            print(f"âš ï¸ æ— æ³•æ³¨å†Œå­—ä½“ {font_path}: {e}")
            continue
    
    # å¦‚æœæ— æ³•æ³¨å†ŒTrueTypeå­—ä½“ï¼Œä½¿ç”¨å†…ç½®çš„CIDå­—ä½“
    if not font_registered:
        try:
            pdfmetrics.registerFont(UnicodeCIDFont('STSong-Light'))
            font_name = 'STSong-Light'
            print("âœ“ ä½¿ç”¨å†…ç½®CIDå­—ä½“: STSong-Light")
        except:
            try:
                pdfmetrics.registerFont(UnicodeCIDFont('HeiseiMin-W3'))
                font_name = 'HeiseiMin-W3'
                print("âœ“ ä½¿ç”¨å†…ç½®CIDå­—ä½“: HeiseiMin-W3")
            except:
                font_name = 'Helvetica'
                print("âš ï¸ æ— æ³•åŠ è½½Unicodeå­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆå¯èƒ½æ— æ³•æ˜¾ç¤ºç‰¹æ®Šç¬¦å·ï¼‰")

    # å°è¯•æ³¨å†Œâ€œç¬¦å·/ä¸Šã€ä¸‹æ ‡â€å¤‡ç”¨å­—ä½“ï¼Œå¹¶åœ¨æ®µè½å†…å¯¹ç¼ºå­—å­—ç¬¦è¿›è¡ŒæŒ‰éœ€åˆ‡æ¢
    fallback_font_name = None
    fallback_candidates = []
    if os.path.isdir(local_font_dir):
        fallback_candidates.extend([
            os.path.join(local_font_dir, 'NotoSansMath-Regular.otf'),
            os.path.join(local_font_dir, 'NotoSansMath-Regular.ttf'),
            os.path.join(local_font_dir, 'DejaVuSans.ttf'),
            os.path.join(local_font_dir, 'NotoSansSymbols2-Regular.ttf'),
        ])
    fallback_candidates.extend([
        '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
        '/usr/share/fonts/opentype/noto/NotoSansMath-Regular.otf',
        '/usr/share/fonts/opentype/noto/NotoSansMath-Regular.ttf',
        '/usr/share/fonts/opentype/noto/NotoSansSymbols2-Regular.ttf',
        '/Library/Fonts/DejaVuSans.ttf',
    ])

    for fp in fallback_candidates:
        try:
            if os.path.exists(fp):
                pdfmetrics.registerFont(TTFont('UnicodeFallback', fp))
                fallback_font_name = 'UnicodeFallback'
                print(f"âœ“ æˆåŠŸæ³¨å†Œå¤‡ç”¨å­—ä½“: {fp}")
                break
        except Exception as e:
            print(f"âš ï¸ æ— æ³•æ³¨å†Œå¤‡ç”¨å­—ä½“ {fp}: {e}")
            continue

    # åŒ…è£…ä¸€ä¸ªå·¥å…·ï¼šå¯¹æ–‡æœ¬ä¸­ä¸Š/ä¸‹æ ‡å­—ç¬¦ç”¨å¤‡ç”¨å­—ä½“æ¸²æŸ“ï¼Œé¿å…ç¼ºå­—å½¢
    import html as _html
    def _escape_html(s: str) -> str:
        return s.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')

    def _apply_supsub_fallback(s: str) -> str:
        t = _escape_html(s)
        if not fallback_font_name:
            return t
        def need_fallback(cp: int) -> bool:
            # ä¸Š/ä¸‹æ ‡
            if cp in (0x00B2, 0x00B3, 0x00B9) or 0x2070 <= cp <= 0x209F or 0x2080 <= cp <= 0x208E:
                return True
            # å¸Œè…Šå­—æ¯
            if 0x0370 <= cp <= 0x03FF:
                return True
            # æ•°å­¦å’ŒæŠ€æœ¯ç¬¦å·å¸¸è§åŒºæ®µ
            if 0x2100 <= cp <= 0x214F:
                return True
            if 0x2190 <= cp <= 0x21FF:
                return True
            if 0x2200 <= cp <= 0x22FF:
                return True
            if 0x25A0 <= cp <= 0x25FF:
                return True
            return False
        out = []
        open_tag = False
        for ch in t:
            cp = ord(ch)
            if need_fallback(cp):
                if not open_tag:
                    out.append(f'<font name="{fallback_font_name}">')
                    open_tag = True
                out.append(ch)
            else:
                if open_tag:
                    out.append('</font>')
                    open_tag = False
                out.append(ch)
        if open_tag:
            out.append('</font>')
        return ''.join(out)
    
    # åˆ›å»ºä¸­æ–‡æ ·å¼
    chinese_style = ParagraphStyle(
        'Chinese',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=11,
        leading=16,
        alignment=TA_JUSTIFY,
        wordWrap='CJK',
    )
    chinese_title = ParagraphStyle(
        'ChineseTitle',
        parent=styles['Title'],
        fontName=font_name,
        fontSize=20,
        leading=28,
        alignment=TA_CENTER,
        spaceAfter=20,
    )
    chinese_heading1 = ParagraphStyle(
        'ChineseHeading1',
        parent=styles['Heading1'],
        fontName=font_name,
        fontSize=16,
        leading=22,
        spaceAfter=12,
        spaceBefore=12,
    )
    chinese_heading2 = ParagraphStyle(
        'ChineseHeading2',
        parent=styles['Heading2'],
        fontName=font_name,
        fontSize=14,
        leading=20,
        spaceAfter=10,
        spaceBefore=10,
    )
    
    # å¤„ç†Markdownæ–‡æœ¬
    lines = markdown_text.split('\n')
    
    for line in lines:
        line = line.strip()
        
        if not line:
            story.append(Spacer(1, 0.15*inch))
            continue
        
        # å¤„ç†æ ‡é¢˜
        if line.startswith('#'):
            level = len(line) - len(line.lstrip('#'))
            text = line.lstrip('#').strip()
            
            # æ¸…ç†Unicodeå­—ç¬¦ï¼ˆæ ‡é¢˜å·²åœ¨æ•´ä½“æ¸…ç†è¿‡ï¼Œè¿™é‡Œä¸éœ€è¦å†æ¬¡æ¸…ç†ï¼‰
            # text = clean_unicode_characters(text, debug=False)
            
            # å¤„ç†æ•°å­¦å…¬å¼
            def replace_math(match):
                latex = match.group(1)
                return convert_latex_to_unicode(latex)
            
            text = re.sub(r'\$([^\$]+)\$', replace_math, text)
            text = re.sub(r'\$\$([^\$]+)\$\$', replace_math, text)
            
            # HTMLè½¬ä¹‰ + å¯¹ä¸Š/ä¸‹æ ‡å­—ç¬¦åº”ç”¨å¤‡ç”¨å­—ä½“
            text = _apply_supsub_fallback(text)
            
            if level == 1:
                p = Paragraph(text, chinese_title)
                story.append(p)
                story.append(Spacer(1, 0.3*inch))
            elif level == 2:
                p = Paragraph(text, chinese_heading1)
                story.append(p)
                story.append(Spacer(1, 0.2*inch))
            else:
                p = Paragraph(text, chinese_heading2)
                story.append(p)
                story.append(Spacer(1, 0.15*inch))
        else:
            # å¤„ç†å›¾ç‰‡æ ‡è®°
            if line.startswith('!['):
                try:
                    # åŒ¹é… Markdown å›¾ç‰‡è¯­æ³•: ![alt](url)
                    match = re.match(r'!\[(.*?)\]\((.*?)\)', line)
                    if match:
                        alt_text = match.group(1)
                        image_data = match.group(2)
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ base64 å›¾ç‰‡
                        if image_data.startswith('data:image'):
                            # æå– base64 æ•°æ®
                            base64_match = re.search(r'base64,(.+)', image_data)
                            if base64_match:
                                base64_str = base64_match.group(1)
                                try:
                                    img_data = base64.b64decode(base64_str)
                                    img_buffer = BytesIO(img_data)
                                    img = Image(img_buffer)
                                    
                                    # è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥é€‚åº”é¡µé¢
                                    max_width = 6*inch
                                    max_height = 8*inch
                                    if img.drawWidth > max_width:
                                        ratio = max_width / img.drawWidth
                                        img.drawWidth = max_width
                                        img.drawHeight = img.drawHeight * ratio
                                    if img.drawHeight > max_height:
                                        ratio = max_height / img.drawHeight
                                        img.drawHeight = max_height
                                        img.drawWidth = img.drawWidth * ratio
                                    
                                    story.append(img)
                                    story.append(Spacer(1, 0.1*inch))
                                    print(f"âœ“ æˆåŠŸæ·»åŠ å›¾ç‰‡: {alt_text}")
                                except Exception as e:
                                    print(f"âš ï¸ å¤„ç†base64å›¾ç‰‡å¤±è´¥: {e}")
                                    # æ·»åŠ å›¾ç‰‡è¯´æ˜ä½œä¸ºæ›¿ä»£
                                    if alt_text:
                                        # altæ–‡æœ¬å·²åœ¨æ•´ä½“æ¸…ç†è¿‡
                                        p = Paragraph(f"[å›¾ç‰‡: {alt_text}]", chinese_style)
                                        story.append(p)
                        else:
                            # URL å›¾ç‰‡ï¼ˆæš‚ä¸æ”¯æŒï¼Œæ˜¾ç¤ºè¯´æ˜ï¼‰
                            if alt_text:
                                # altæ–‡æœ¬å·²åœ¨æ•´ä½“æ¸…ç†è¿‡
                                p = Paragraph(f"[å›¾ç‰‡: {alt_text}]", chinese_style)
                                story.append(p)
                                story.append(Spacer(1, 0.08*inch))
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†å›¾ç‰‡è¡Œå‡ºé”™: {e}, å†…å®¹: {line[:100]}...")
                continue
            
            # è·³è¿‡ HTML img æ ‡ç­¾ï¼ˆå¯èƒ½éœ€è¦é¢å¤–å¤„ç†ï¼‰
            if line.startswith('<img'):
                print(f"âš ï¸ è·³è¿‡ HTML img æ ‡ç­¾: {line[:100]}...")
                continue
            
            # å¤„ç†æ™®é€šæ–‡æœ¬
            text = line
            
            # æ¸…ç†Unicodeå­—ç¬¦ï¼ˆæ–‡æœ¬å·²åœ¨æ•´ä½“æ¸…ç†è¿‡ï¼Œè¿™é‡Œä¸éœ€è¦å†æ¬¡æ¸…ç†ï¼‰
            # text = clean_unicode_characters(text, debug=False)
            
            # å¤„ç†æ•°å­¦å…¬å¼ $...$ å’Œ $$...$$
            def replace_math(match):
                latex = match.group(1)
                return convert_latex_to_unicode(latex)
            
            # å…ˆå¤„ç†è¡Œå†…å…¬å¼ $...$
            text = re.sub(r'\$([^\$]+)\$', replace_math, text)
            
            # å¤„ç†è¡Œé—´å…¬å¼ $$...$$ï¼ˆé€šå¸¸å•ç‹¬ä¸€è¡Œï¼‰
            text = re.sub(r'\$\$([^\$]+)\$\$', replace_math, text)
            
            # HTMLè½¬ä¹‰ + å¯¹ä¸Š/ä¸‹æ ‡å­—ç¬¦åº”ç”¨å¤‡ç”¨å­—ä½“ï¼ˆåœ¨å…¬å¼è½¬æ¢ä¹‹åï¼‰
            text = _apply_supsub_fallback(text)
            
            # å¤„ç†Markdownæ ¼å¼
            text = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', text)  # ç²—ä½“
            text = re.sub(r'\*(.+?)\*', r'<i>\1</i>', text)  # æ–œä½“
            text = re.sub(r'`(.+?)`', r'<font face="Courier">\1</font>', text)  # ä»£ç 
            
            if text.strip():
                try:
                    p = Paragraph(text, chinese_style)
                    story.append(p)
                    story.append(Spacer(1, 0.08*inch))
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†æ®µè½å‡ºé”™: {e}, æ–‡æœ¬: {text[:50]}...")
                    continue
    
    # ç”ŸæˆPDF
    try:
        doc.build(story)
        print(f"âœ“ PDFç”ŸæˆæˆåŠŸ: {output_path}")
    except Exception as e:
        print(f"âŒ PDFç”Ÿæˆå¤±è´¥: {e}")
        raise


@app.route('/')
def index():
    """ä¸»é¡µ - ç›´æ¥æ˜¾ç¤ºå®Œæ•´ç•Œé¢"""
    try:
        return render_template('index.html')
    except Exception as e:
        return f"<h1>æ¨¡æ¿åŠ è½½é”™è¯¯</h1><p>{str(e)}</p>"

@app.route('/full')
def full():
    """å®Œæ•´ç•Œé¢"""
    try:
        return render_template('index.html')
    except Exception as e:
        return f"<h1>æ¨¡æ¿åŠ è½½é”™è¯¯</h1><p>{str(e)}</p>"

@app.route('/health')
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'running',
        'message': 'PDFç¿»è¯‘å™¨æœåŠ¡æ­£å¸¸',
        'timestamp': time.time()
    })

@app.route('/test')
def test():
    """æµ‹è¯•è·¯ç”±"""
    return jsonify({'status': 'ok', 'message': 'PDFç¿»è¯‘å™¨è¿è¡Œæ­£å¸¸'})


@app.route('/translate', methods=['POST'])
def translate_pdf():
    """å¤„ç†PDFç¿»è¯‘è¯·æ±‚"""
    if 'file' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'}), 400
    
    file = request.files['file']
    
    if file.filename == '':
        return jsonify({'error': 'æ–‡ä»¶åä¸ºç©º'}), 400
    
    if not file.filename.endswith('.pdf'):
        return jsonify({'error': 'åªæ”¯æŒPDFæ–‡ä»¶'}), 400
    
    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        upload_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
        file.save(upload_path)

        # è§£æ MinerU é…ç½®
        mineru_options = {
            "is_ocr": _to_bool(request.form.get('is_ocr'), True),
            "include_image_base64": _to_bool(request.form.get('include_image_base64'), True),
            "formula_enable": _to_bool(request.form.get('formula_enable'), True),
            "table_enable": _to_bool(request.form.get('table_enable'), True),
            "layout_model": request.form.get('layout_model', 'doclayout_yolo'),
            "output_format": request.form.get('output_format', 'md'),
        }

        end_pages_input = request.form.get('end_pages')
        print(f"ä»å‰ç«¯æ¥æ”¶åˆ°çš„ end_pages: '{end_pages_input}'")
        if end_pages_input and end_pages_input.strip():
            # end_pages æ˜¯å¤„ç†åˆ°ç¬¬å‡ é¡µä¸ºæ­¢çš„æ•°å­—
            mineru_options['end_pages'] = end_pages_input.strip()
            print(f"âœ“ è®¾ç½® end_pages = '{end_pages_input.strip()}' (å¤„ç†ç¬¬1é¡µåˆ°ç¬¬{end_pages_input.strip()}é¡µ)")

        language = request.form.get('language')
        if language:
            mineru_options['language'] = language.strip()
        
        # è·å–å‰ç«¯ä¼ æ¥çš„APIé…ç½®
        parse_api_token = request.form.get('parse_api_token')
        translate_api_url = request.form.get('translate_api_url')
        translate_api_key = request.form.get('translate_api_key')
        translate_api_model = request.form.get('translate_api_model')
        
        # æ‰“å°APIé…ç½®ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        print("\n" + "=" * 50)
        print("APIé…ç½®ä¿¡æ¯:")
        if parse_api_token:
            print(f"âœ“ ä½¿ç”¨è‡ªå®šä¹‰è§£æAPI Token: {parse_api_token[:10]}...")
        else:
            print("  ä½¿ç”¨é»˜è®¤è§£æAPIé…ç½®")
        
        if translate_api_url:
            print(f"âœ“ ä½¿ç”¨è‡ªå®šä¹‰ç¿»è¯‘API URL: {translate_api_url}")
        else:
            print("  ä½¿ç”¨é»˜è®¤ç¿»è¯‘API URL")
            
        if translate_api_key:
            print(f"âœ“ ä½¿ç”¨è‡ªå®šä¹‰ç¿»è¯‘API Key: {translate_api_key[:10]}...")
        else:
            print("  ä½¿ç”¨é»˜è®¤ç¿»è¯‘API Key")
            
        if translate_api_model:
            print(f"âœ“ ä½¿ç”¨è‡ªå®šä¹‰ç¿»è¯‘æ¨¡å‹: {translate_api_model}")
        else:
            print("  ä½¿ç”¨é»˜è®¤ç¿»è¯‘æ¨¡å‹")
        print("=" * 50 + "\n")
        
        # 1. ä½¿ç”¨MinerUè§£æPDF
        print("æ­£åœ¨è§£æPDF...")
        result = parse_pdf_with_mineru(upload_path, mineru_options, api_token=parse_api_token)
        task_id = result.get("task_id")
        
        if not task_id:
            return jsonify({'error': 'MinerUä»»åŠ¡åˆ›å»ºå¤±è´¥'}), 500
        
        print(f"ä»»åŠ¡ID: {task_id}")
        
        # 2. ç­‰å¾…MinerUå¤„ç†å®Œæˆ
        print("ç­‰å¾…MinerUå¤„ç†...")
        task_result = poll_mineru_task(task_id, api_token=parse_api_token)
        
        # 3. è·å–è§£æç»“æœ
        if task_result.get("status") != "success":
            return jsonify({'error': 'PDFè§£æå¤±è´¥'}), 500
        
        # ä¿å­˜ä»»åŠ¡ç»“æœç”¨äºè°ƒè¯•
        print(f"ä»»åŠ¡ç»“æœ: {json.dumps(task_result, indent=2, ensure_ascii=False)}")
        
        # è·å–Markdownå†…å®¹
        markdown_content = None
        if "output" in task_result:
            output = task_result["output"]
            
            # å°è¯•ä» segments è·å–å†…å®¹
            if "segments" in output and isinstance(output["segments"], list):
                segments = output["segments"]
                print(f"âœ“ æ‰¾åˆ° {len(segments)} ä¸ªå†…å®¹æ®µ")
                
                # åˆå¹¶æ‰€æœ‰segmentsçš„content
                content_parts = []
                for segment in segments:
                    if "content" in segment:
                        content_parts.append(segment["content"])
                
                if content_parts:
                    markdown_content = "\n\n".join(content_parts)
                    print(f"âœ“ ä» segments è·å–å†…å®¹ï¼Œæ€»é•¿åº¦: {len(markdown_content)}")
                else:
                    print("âš ï¸ segmentsä¸­æ²¡æœ‰contentå­—æ®µ")
            
            # å°è¯•è·å– text_result
            elif "text_result" in output:
                markdown_content = output["text_result"]
                print("âœ“ ä» text_result è·å–å†…å®¹")
            
            # å°è¯•ä¸‹è½½ file_url
            elif "file_url" in output:
                file_url = output["file_url"]
                print(f"ä¸‹è½½æ–‡ä»¶: {file_url}")
                response = requests.get(file_url, timeout=30)
                markdown_content = response.text
                print(f"âœ“ ä¸‹è½½å†…å®¹é•¿åº¦: {len(markdown_content)}")
            
            # å°è¯•è·å– content å­—æ®µ
            elif "content" in output:
                markdown_content = output["content"]
                print("âœ“ ä» content è·å–å†…å®¹")
            
            else:
                print(f"âš ï¸ output å­—æ®µä¸åŒ…å«é¢„æœŸçš„å†…å®¹ï¼Œå­—æ®µåˆ—è¡¨: {list(output.keys())}")
        else:
            print("âš ï¸ ä»»åŠ¡ç»“æœä¸­æ²¡æœ‰ output å­—æ®µ")
        
        if not markdown_content:
            error_msg = f'æ— æ³•è·å–è§£æå†…å®¹ã€‚ä»»åŠ¡ç»“æœ: {json.dumps(task_result, ensure_ascii=False)}'
            print(error_msg)
            return jsonify({'error': 'æ— æ³•è·å–è§£æå†…å®¹ï¼Œè¯·æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—'}), 500
        
        # ä¿å­˜ä»»åŠ¡ç»“æœåˆ°æ–‡ä»¶
        task_file = os.path.join(app.config['UPLOAD_FOLDER'], f"task_{task_id}.json")
        with open(task_file, "w", encoding='utf-8') as f:
            json.dump(task_result, f, indent=4, ensure_ascii=False)
        print(f"âœ“ ä»»åŠ¡ç»“æœå·²ä¿å­˜åˆ°: {task_file}")
        
        # ä¿å­˜åŸå§‹ Markdown å†…å®¹åˆ°æ–‡ä»¶
        markdown_file = os.path.join(app.config['UPLOAD_FOLDER'], f"markdown_{task_id}.md")
        with open(markdown_file, "w", encoding='utf-8') as f:
            f.write(markdown_content)
        print(f"âœ“ åŸå§‹Markdownå·²ä¿å­˜åˆ°: {markdown_file}")
        print(f"âœ“ Markdownå†…å®¹é•¿åº¦: {len(markdown_content)}")
        
        print("PDFè§£ææˆåŠŸï¼")
        
        # 4. æ ¹æ®ç¿»è¯‘æ¨¡å¼é€‰æ‹©ç¿»è¯‘æ–¹æ³•
        translation_mode = request.form.get('translation_mode', 'hybrid')  # é»˜è®¤ä½¿ç”¨æ··åˆæ¨¡å¼
        
        print("\n" + "="*50)
        print(f"ç¿»è¯‘æ¨¡å¼: {translation_mode}")
        print("="*50)
        
        if translation_mode == 'hybrid':
            # æ··åˆæ¨¡å¼ï¼šDeepLX + AIå…¬å¼ä¿®æ­£ï¼ˆæ¨èï¼Œå¿«é€Ÿä¸”å‡†ç¡®ï¼‰
            print("ä½¿ç”¨æ··åˆç¿»è¯‘æ¨¡å¼ï¼ˆDeepLXå¿«é€Ÿç¿»è¯‘ + AIå…¬å¼ä¿®æ­£ï¼‰")
            translated_content = translate_markdown_hybrid(
                markdown_content,
                api_url=translate_api_url,
                api_key=translate_api_key,
                model=translate_api_model
            )
        elif translation_mode == 'ai':
            # çº¯AIæ¨¡å¼ï¼šè´¨é‡æœ€é«˜ä½†é€Ÿåº¦æ…¢
            print("ä½¿ç”¨çº¯AIç¿»è¯‘æ¨¡å¼ï¼ˆé«˜è´¨é‡ä½†è¾ƒæ…¢ï¼‰")
            translated_content = translate_markdown_content_with_ai(
                markdown_content,
                api_url=translate_api_url,
                api_key=translate_api_key,
                model=translate_api_model
            )
        elif translation_mode == 'deeplx':
            # çº¯DeepLXæ¨¡å¼ï¼šé€Ÿåº¦æœ€å¿«ä½†å…¬å¼å¯èƒ½æœ‰é—®é¢˜
            print("ä½¿ç”¨çº¯DeepLXç¿»è¯‘æ¨¡å¼ï¼ˆæœ€å¿«ä½†å…¬å¼å¯èƒ½éœ€æ‰‹åŠ¨ä¿®æ­£ï¼‰")
            translated_content = translate_markdown_content(markdown_content)
        else:
            # é»˜è®¤ä½¿ç”¨æ··åˆæ¨¡å¼
            print("æœªçŸ¥ç¿»è¯‘æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤æ··åˆæ¨¡å¼")
            translated_content = translate_markdown_hybrid(
                markdown_content,
                api_url=translate_api_url,
                api_key=translate_api_key,
                model=translate_api_model
            )
        
        print("="*50)
        print("âœ“ ç¿»è¯‘å®Œæˆï¼\n")
        
        # ä¿å­˜ç¿»è¯‘åçš„å†…å®¹
        translated_file = os.path.join(app.config['UPLOAD_FOLDER'], f"translated_{task_id}.md")
        with open(translated_file, "w", encoding='utf-8') as f:
            f.write(translated_content)
        print(f"âœ“ ç¿»è¯‘åçš„Markdownå·²ä¿å­˜åˆ°: {translated_file}")
        
        print("ç”ŸæˆPDF...")
        
        # 5. ç”Ÿæˆç¿»è¯‘åçš„PDF
        output_filename = f"translated_{os.path.splitext(file.filename)[0]}.pdf"
        output_path = os.path.join(app.config['UPLOAD_FOLDER'], output_filename)
        markdown_to_pdf(translated_content, output_path)
        
        print("PDFç”ŸæˆæˆåŠŸï¼")
        
        # 6. è¿”å›æ–‡ä»¶
        return send_file(
            output_path,
            as_attachment=True,
            download_name=output_filename,
            mimetype='application/pdf'
        )
        
    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")
        return jsonify({'error': str(e)}), 500
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if os.path.exists(upload_path):
                os.remove(upload_path)
        except:
            pass


if __name__ == '__main__':
    print("å¯åŠ¨PDFç¿»è¯‘å™¨...")
    print("è®¿é—® http://localhost:8000 ä½¿ç”¨åº”ç”¨")
    app.run(debug=False, host='0.0.0.0', port=8000)
